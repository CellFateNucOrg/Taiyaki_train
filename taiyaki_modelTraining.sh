#! /bin/bash
## Taiyaki model training, round 1 - optimizing canonical base calling

## Allocate resources
#SBATCH --time=7-00:00:00
#SBATCH --partition=all
#SBATCH --gres=gpu:1 ## reserve GPU (1 means yes, i.e. GPU will be reserved)
#SBATCH --mem=96GB

## job name
##SBATCH --job-name="trainModel"


# retrieve variables from command line
varSettingsFile=$1 	# name of configuration file
trainingRound=$2
echo "### Taiyaki model training ###"
echo "Configuration file: " ${varSettingsFile}
echo "Training round: " ${trainingRound}

trainingIndex=$((trainingRound-1))


#################
# read settings #
#################
source $varSettingsFile


#####################
# setting variables #
#####################
# name of training directory and model files#
modNamesSelection=$(for i in ${indicesOfSelection[*]}; \
	do printf "%s__" ${modificationsOfInterest[$i]}; \
	done)	# concatenates specific elements of array modificationsOfInterest (specified in array indicesOfSelection) with "__" as delimiter for concatenation
modNamesSelection=$(echo ${modNamesSelection%__})  # %__ strips the trailing "__" from the variable name

# directory for training results
trainingDir=${modelDir}/training${trainingRound}_exp${expName}_${modNamesSelection}_${modelDirNameAppendix[${trainingIndex}]}
#mkdir -p ${trainingDir} # not required - the Taiyaki module creates the directory itself (and in fact stops if the directory already exists

# input model file #
if [ ${trainingRound} == 1 ]
	then inputModelFile=${TAIYAKI_DIR}/models/mGru_cat_mod_flipflop.py
elif [ ${trainingRound} == 2 ]
	then inputModelDir=${modelDir}/training1_exp${expName}_${modNamesSelection}_${modelDirNameAppendix[0]}  # modelDirNameAppendix[0] --> directory of first training round
	inputModelFile=$(ls ${inputModelDir}/*.checkpoint | tail -1)
fi

# mod_factor for training #
modFactorVar=${trainingModFactor[${trainingIndex}]}  # controls the proportion of the training loss attributed to the modified base output stream

# mapped reads #
mappedReadFile=${modelDir}/modbases_${expName}_*.hdf5


############################################
# check if conditions for training are met #
############################################
mappedReadsAvailable=$(ls -1 ${modelDir}/*.hdf5 2>/dev/null | wc -l)
training_1_available=$(ll -1 ${modelDir}/training1*/*.checkpoint 2>/dev/null | wc -l)
echo modelDir ${modelDir}
echo training_1_available ${training_1_available}
if [ ${mappedReadsAvailable} == 0 ]; then echo "No file containing mapped reads available"; exit; fi
#if [ ${trainingRound} == 2 ] && [ ${training_1_available} == 0 ]
#then echo "Please carry out training round 1 before proceeding."; exit;
#fi


####################
# activate taiyaki #
####################
source ${TAIYAKI_DIR}/venv/bin/activate


######################
# Run model training #
######################
# Two rounds of training are performed: 
# the first round down-weights learning the modified bases in favour a good canonical call, 
# the second round then focuses on learning the conditional prediction of whether a base is modified.
if [ ${trainingRound} == 1 ]
then echo -e "Starting Taiyaki model training, round 1 - optimizing canonical base calling..."
	echo "Using default model (${TAIYAKI_DIR}/models/mGru_cat_mod_flipflop.py)."
elif [ ${trainingRound} == 2 ]
then echo -e "Starting Taiyaki model training,  round 2 - conditional recognition of modified bases..."
	echo "Using last checkpoint of model of first training round (${inputModelFile})."
fi

echo "Running on GPUs..."
echo -e "Saving model files to ${trainingDir}" "\n"

###################
# training module #
###################
### There has been a Taiyaki-update (version 5.0) on Sept. 12 2019. ###
# Unlike in version 4.1.0 this script is written for, there is no separate train_mod_flipflop.py module any more,
# instead only the single module train_flipflop.py.
### It may be necessary to adjust the code below ! ###

train_mod_flipflop.py --save_every 1500 --device cuda:0 --mod_factor ${modFactorVar}  `# checkpoint is saved after every n epochs (save_every); --mod_factor argument controls the proportion of the training loss attributed to the modified base output stream in comparison to the canonical base output stream` \
	--outdir ${trainingDir}  `# output directory for trained model (will be created by train_mod_flipflop.py` \
	${inputModelFile}  `# file containing initial model` \
	${mappedReadFile}  `# hdf5-model file. generated by read-mapping (prepare_mapped.reads.py)`

